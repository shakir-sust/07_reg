---
title: "Regression"
format: html
---

# Learning objectives  
Today's learning objectives are to:  
-   Explore a data set containing corn grain yield response to seeding rate coming from a *well-conducted randomized complete-block design*.

- Complete formal analysis of four models:
  - intercept-only  
  - linear (intercept + slope)  
  - quadratic  
  - linear-plateau  

- Use bootstrap to create confidence intervals around regression lines.  
  
-   Compare all models using **AIC**. Which one fits the data best? Choose one to proceed and use in the next steps.

-   Use regression for finding level of input (seeds/ha) that optimize crop output (yield).

# Introduction  
# Regression use - Finding optimum input level

One of the main goals of applying different levels of an input (e.g., seeding rate) and measuring its effect on an output (e.g., yield) is to estimate the **optimum input level that maximizes the output**.

Here, our input is seeding rate, but it could be a range of other types of inputs:  
  - Fertilizer  
  - Pesticide  
  - Irrigation volume  
  - Temperature and air relative humidity (controlled environments)   
  - Planting date  
  - Others?

Because both the response variable (i.e., corn yield) and explanatory variable (i.e., seeding rate) are **numerical**, we can analyze this in a **regression** approach (instead of ANOVA).  

## Different input x output responses

Anytime we have this input x output **numerical** relationship, a few different patterns can emerge.

```{r input output relationships figure, echo=F}
#knitr::include_graphics("../data/ior.png")
```

Talk about each of these patterns.

# 1) Setup  

Here is where we load the packages we will use.

```{r setup}
#| message: false
#| warning: false

#install.packages("broom.mixed")
#install.packages("nlraa")
#install.packages("lmerTest")
#install.packages("nlme")
#install.packages("metrica")
#install.packages("knitr")

# Loading packages
library(tidyverse) # for data wrangling and plotting
library(janitor) # clean column names
library(lmerTest) # for mixed-effect modeling
library(broom.mixed) # for residual diagnostics
library(knitr) # for figure displaying
library(nlme) # for non-linear modeling
library(car)
library(nlraa) # for starting value functions
library(metrica) # for rmse

```

Reading data and doing some light wrangling.  
```{r}
#| message: false
reg_dfw <- read_csv("../data/reg.csv") %>%
  clean_names() %>% #to standardize the variable names in terms of lower case and upper case
  mutate(rep = factor(rep))

reg_dfw
```

This study was a randomized complete block design (RCBD) with four blocks.  

The treatment factor is seeding rate (in 1,000 seeds per ha) with five levels:  
  - 40  
  - 60  
  - 80  
  - 100  
  - 120  

The response variable was corn yield in Mg/ha.  


# 2) EDA  
```{r summary}
summary(reg_dfw)
```
Yield ranging from 7.8 to 15.6 Mg/ha.  

```{r reg exp boxplot}
ggplot(data = reg_dfw,
       aes(x = factor(sr_ksha), #factor(sr_ksha) is to treat 
           y = yield_mgha
           )) +
  geom_boxplot() 

```

What is going on with this boxplot?

```{r reg plot point + smooth, message=FALSE, warning=FALSE}
ggplot(reg_dfw, 
       aes(x = sr_ksha, 
           y = yield_mgha)) +
  geom_point() + #To plot the data points
  geom_smooth() #To add trendline #We use geom_line() only to connect the points with a line
  

```

Let's fit 4 different models to assess which one fits the data the best. 

Our goal is to then use that model to estimate the optimum seeding rate for this study.  

# 3) Intercept-only 
## a) Model  
```{r mod1_int}
# Changing to sum-to-zero contrast
options(contrasts = c("contr.sum", "contr.poly"))

# Model fitting
mod1_int <- lmer(yield_mgha ~ (1|rep),
                 data = reg_dfw
                 ) #lmer is for either random effect of mixed efect model

# Summary
summary(mod1_int)

```

## b) Model Assumptions
```{r mod1 augmenting}
# Augmenting and adding perason standardized residuals
mod1_int_aug <- augment(mod1_int) %>%
  mutate(.stdresid = resid(mod1_int, 
                           type = "pearson", #to get pearson residual
                           scaled = T)) %>% #to get normalized i.e., scaled residual to detect outliers
  left_join(reg_dfw) #to bring back the seeding rate (x) into the model


mod1_int_aug
```

### Within-group errors are iid ~ N(0, var2)

```{r mod1 Standardized Residuals vs. Fitted, message=FALSE, warning=FALSE}
ggplot(mod1_int_aug, 
       aes(x = .fitted, 
           y = .stdresid))+
  geom_hline(yintercept = 0, 
             color = "red")+ #To add a horizontal line across 0
  geom_point(size = 3, 
             alpha = .7)+
  geom_smooth()
```

Residuals looking suspicious. There is an increasing pattern.

For now, let's keep going.

```{r mod1 Quantile-Quantile}
ggplot(mod1_int_aug, 
       aes(sample = .stdresid))+
  stat_qq()+
  stat_qq_line()
```
Some deviations at the tails, not too bad.  

### Random effects are iid ~ N(0,var1)

On this plot, looking for normality.

```{r mod1 QQ plot for Location:fRep random effects}
mod1_int_randeff <- ranef(mod1_int)[[1]] 

ggplot(mod1_int_randeff, 
       aes(sample = `(Intercept)`))+
  stat_qq()+
  stat_qq_line()

```
Few observations, nothing alarming.  

## c) Model summary

```{r mod1 ANOVA}
summary(mod1_int)
```

Intercept highly significant! Which does not mean that this is a good/bad model.

## d) Final plot  

```{r mod1 final plot}
ggplot(mod1_int_aug, 
       aes(x = sr_ksha, 
           y = yield_mgha))+
  geom_point(size = 3, 
             alpha = .7) +
  geom_line(aes(y = .fixed))
```

Problem with the plot above:  
- no confidence interval around regression

Solution:  
- we can use bootstrap to create confidence intervals around the regression curve

Bootstrap: Resampling with replacement

First, let's create an data set with all levels of seeding rate we want to get a prediction.  
```{r nd}
nd <- data.frame(sr_ksha = seq(40, 120, 1)) #nd stands for new data #40 is the lowest level, 120 is the hightest level, and we want the increment to happen at a step of 1

nd #To compare all the fit lines for the 4 models, we are creating "nd" in the very beginning and will keep overwriting on it so that we can have a single object that have all the model predicted values and the Confidence Levels for each models. 
```

```{r mod1 better final plot}
# Creating predictions
nd <- nd %>%  #The model is gonna predict based on intercepts
  mutate(mod1_yield_mgha = predict(mod1_int,
                                   nd,
                                   re.form = NA
                                   ))
# Creating function to bootstrap
predict.fun <- function(mod) {
  predict(mod, 
          newdata = nd, 
          re.form = NA)
}

# Bootstrapping for confidence interval
mod1_int_boots <- bootMer(mod1_int, 
                          predict.fun, 
                          nsim = 200) %>% #bootstrapping 200 times
  confint() %>%
  as.data.frame() %>%
  rename(mod1_int_lcl = `2.5 %`,
         mod1_int_upl = `97.5 %`)

mod1_int_boots

nd <- nd %>%
  bind_cols(mod1_int_boots)

nd

# Final plot
ggplot(reg_dfw, 
       aes(x = sr_ksha, 
           y = yield_mgha))+
  geom_point(size = 3, 
             alpha = .7)+
  geom_line(data = nd, 
            aes(y = mod1_yield_mgha), 
            color = "forestgreen") +
  geom_ribbon(data = nd,
              aes(ymin = mod1_int_lcl,
                  ymax = mod1_int_upl,
                  x = sr_ksha
                  ),
              inherit.aes = FALSE,
              alpha = .5
              )
```

Linear thoughts:

Just because p-value (of the intercept) is (highly) significant, it DOES NOT mean the (regression) model is good. Always check residuals and plot!!

Next, let's try a linear (intercept + slope) model.  

# 4) Linear regression  

## a) Model  
```{r mod2 linear model}
# Changing to sum-to-zero contrast
options(contrasts = c("contr.sum", "contr.poly"))

# Model fitting
mod2_lin <- lmer(yield_mgha ~ (1|rep) + sr_ksha, #"(1|rep)" is to set rep as random effect
                 data = reg_dfw
                 )

# Summary
summary(mod2_lin)

```

## b) Model Assumptions
```{r mod2 augmenting}
# Augmenting and adding perason standardized residuals
mod2_lin_aug <- augment(mod2_lin) %>%
  mutate(.stdresid = resid(mod2_lin, 
                           type = "pearson", 
                           scaled = T))


mod2_lin_aug
```

### Within-group errors are iid ~ N(0, var2)

```{r mod2 Standardized Residuals vs. Fitted}
ggplot(mod2_lin_aug, 
       aes(x = .fitted, 
           y = .stdresid))+
  geom_hline(yintercept = 0, color = "red")+
  geom_point(size = 3, alpha = .7)+
  geom_smooth()
```

Residuals looking suspicious! Clear quadratic pattern! We will need to address this problem later.

For now, let's keep going.

```{r mod2 Quantile-Quantile}
ggplot(mod2_lin_aug, 
       aes(sample = .stdresid))+
  stat_qq()+
  stat_qq_line()
```
Tails looking a bit off now.  

### Random effects are iid ~ N(0,var1)

On this plot, looking for normality.

```{r mod2 QQ plot for Location:fRep random effects}
mod2_lin_randeff <- ranef(mod2_lin)[[1]] 

ggplot(mod2_lin_randeff, 
       aes(sample = `(Intercept)`))+
  stat_qq()+
  stat_qq_line()

```
Few points, not too bad.  

## c) Model summary

```{r mod2 ANOVA}
summary(mod2_lin)
```

Intercept and slope for sr_ksha are highly significant!

## d) Final plot  

```{r mod2 final plot}
ggplot(mod2_lin_aug, 
       aes(x = sr_ksha, 
           y = yield_mgha))+
  geom_point(size = 3, 
             alpha = .7) +
  geom_line(aes(y = .fixed)) +
  scale_x_continuous(limits = c(0, 120))
```

Problem with the plot above:  
- no confidence interval around regression

Solution:  
- we can use bootstrap to create confidence intervals around the regression curve

```{r mod2 better final plot}
# Creating predictions
nd <- nd %>%
  mutate(mod2_yield_mgha = predict(mod2_lin, 
                                   nd, 
                                   re.form = NA))

# Bootstrapping for confidence interval
mod2_lin_boots <- bootMer(mod2_lin, 
                          predict.fun, 
                          nsim = 200) %>%
  confint() %>%
  as.data.frame() %>%
  rename(mod2_lin_lcl = `2.5 %`,
         mod2_lin_upl = `97.5 %`)


nd <- nd %>%
  bind_cols(mod2_lin_boots) #To bind the columns

nd

# Final plot
ggplot(reg_dfw, 
       aes(x = sr_ksha, 
           y = yield_mgha))+
  geom_point(size = 3, 
             alpha = .7)+
  geom_line(data = nd, 
            aes(y = mod2_yield_mgha), 
            color = "forestgreen")+
  geom_ribbon(data = nd, 
              aes(x = sr_ksha, 
                  ymin = mod2_lin_lcl,
                  ymax = mod2_lin_upl),
              fill = "gray", 
              alpha = 0.5, 
              inherit.aes = FALSE)
```

# 5) Quadratic regression  
## a) Model

```{r mod3 model}
# Changing to sum-to-zero contrast
options(contrasts = c("contr.sum", "contr.poly"))

# Model fitting
mod3_quad <- lmer(yield_mgha ~ (1|rep) + sr_ksha + I(sr_ksha^2), #We are using lmer() because we are treating blocks as random effect i.e., to run a mixed effects model #I() stands for identity, used to make sure that R understands it is a quadratic term #rep is categorical, and sr_ksha is numeric variable
                  data = reg_dfw
                  )

# Summary
summary(mod3_quad)
```
Here, the "Estimate" for "sr_ksha" is 0.3089371, which is greater than 0. This tells us that there is a positive relationship between seeding rate and yield (based on the slope estimate of the model).

The "Estimate" for the quadratic term "I(sr_ksha^2)" is -0.0016061 which is a negative value -- which indicates that there is a point of maximum in the (upward) quadratic curvature. Oppositely, if the "Estimate" for the quadratic term "I(sr_ksha^2)" were positive, it would mean that we have a point of minimum  in the (downward) quadratic curvature.

## Differnce between regression and ANOVA:

In regression, the explanatory variable(s) (= x) are numerical
In ANOVA, the explanatory variable(s) (= x) are categorical


## b) Model Assumptions
```{r mod3 augmenting}
# Augmenting and adding pearson standardized residuals
mod3_quad_aug <- augment(mod3_quad) %>% #"augment()" function allows to collect all the residual information (along with our original dataframe)
  mutate(.stdresid = resid(mod3_quad, 
                           type = "pearson", 
                           scaled = T))


mod3_quad_aug
```

### Within-group errors are iid ~ N(0, var2)

```{r mod3 Standardized Residuals vs. Fitted}
ggplot(mod3_quad_aug, 
       aes(x = .fitted, 
           y = .stdresid)) + #x = fitted, y = residual #fitted by residual plot
  geom_hline(yintercept = 0, color = "red")+
  geom_point(size = 3, alpha = .7)+
  geom_smooth(method = "lm")
```
Very important note: 
Question: Why do we check assumptions of residuals, and not on the raw data?
Answer: The reason we chech assumptions on residuals in because residuals change based on the model, whereas raw data does not change. When we change the model, we also change the residuals. That's why we chech assumptions on residuals. The residual in the interaction between our data and model. So, if we change the model, the residuals are also going to change. 

Dr. Bastos said: make the model fit your data, not the data fit your model (first).



Residuals are looking better now, no pattern.  

Linear thoughts:

Model assumptions are based on residuals, not raw data!

Notice here that we used the **same data** as before, just changed the model, and that completely changed the residuals (for better, in this case)!

Remember: residual = distance of raw data from model fit [Residual, e = observed data (y_i) - predicted data (y_hat)]. If model changes, residual changes, even when same underlying raw data is used.


```{r mod3 Quantile-Quantile}
ggplot(mod3_quad_aug, 
       aes(sample = .stdresid))+
  stat_qq()+
  stat_qq_line()
```
Looking better than before, especially tails.  

### Random effects are iid ~ N(0,var1)

On this plot, looking for normality.

```{r mod3 QQ plot for Rep random effect}
mod3_quad_randeff <- ranef(mod3_quad)[[1]] 

ggplot(mod3_quad_randeff, 
       aes(sample = `(Intercept)`))+
  stat_qq()+
  stat_qq_line()

```
Looks ok.  

## c) Model summary

```{r mod3 ANOVA}
summary(mod3_quad)

```

Slope and curvature for sr_ksha are highly significant!

## d) Final plot

```{r mod3 final plot}
ggplot(mod3_quad_aug, 
       aes(x = sr_ksha, 
           y = yield_mgha))+
  geom_point(size = 3, alpha = .7)+
  geom_line(aes(y = .fixed), 
            color = "forestgreen")

```

Problems with the plot:   
- regression curve on the plot above is not continuous because it is based on our original levels of SR (40, 60, 80, 100, 120 k seeds/ha).

-   similar to linear regression, no confidence interval.

Solutions:   
- to create a smoother look, we can simulate some SR data, use the model above to predict their yield, and plot that as a line.

-   we can use bootstrap to create confidence intervals around the regression curve

```{r mod3 better final plot}
# Creating predictions
nd <- nd %>%
  mutate(mod3_yield_mgha = predict(mod3_quad, 
                                   nd, 
                                   re.form = NA))

# Bootstrapping
mod3_quad_boots <- bootMer(mod3_quad, 
                           predict.fun, 
                           nsim = 200) %>%
  confint() %>%
  as.data.frame() %>%
  rename(mod3_quad_lcl = `2.5 %`,
         mod3_quad_upl = `97.5 %`)


nd <- nd %>%
  bind_cols(mod3_quad_boots)

nd

# Final plot
ggplot(reg_dfw, 
       aes(x = sr_ksha, 
           y = yield_mgha))+
  geom_point(size = 3, alpha = .7)+
  geom_line(data = nd, 
            aes(y = mod3_yield_mgha), 
            color = "forestgreen")+
  geom_ribbon(data = nd, aes(x = sr_ksha, 
                             ymin = mod3_quad_lcl,
                             ymax = mod3_quad_upl),
              fill = "gray", 
              alpha = 0.5, 
              inherit.aes = FALSE)



```

Now, which one fits the data best?
Which one should we chose for finding the optimum, or predicting new data?  
Answer: Quadratic model

In our data set,   
- We know there is a yield response to SR (so intercept-only model is not a good candidate),  
- We know we have achieved a maximum point (so linear is not a good candidate)  
- We have already fit the quadratic model. (i.e., there is a point of maximum)  
- We can fit the linear-plateau (LP) model. (Linear-plateau (LP) is the first non-linear model that we are gonna run in this class)

So, let's fit a LP model and then compare it to the quadratic.  
After that, we can choose the model that best fit our data and use it to extract the optimum seeding rate.

**Very important note:**

Regardless of the curvature in a quadratic model, a quadratic model is also a linear model [just like the "intercept" model and "linear (= intercept + slope)" model].

What makes a model linear or non-linear is how the model parameters are estimated. If the model parameter(s) has non-linearity in the model, only the we can say that it is a non-linear model.

The linear-plateau (LP) is gonna be the first non-linear model we are gonna see here because it has non-linearities in the parameters of the model itself, and not in the way the model looks like (in terms of curvature) once it has been fit to the data.

The "intercept" model and "linear (= intercept + slope)" model are linear not because how the curvature of the models look (like linear), but because how the parameters of the models were estimated (i.e., the model parameters did not have non-linearity) i.e., the model parameters were estimated in a linear fashion.

Liinear-plateau (LP) is gonna have a break point i.e., the curve increases up to a certain point, then it breaks at the breaking point, and then there is a plateau after that. That's why it is called linear-plateau (LP).

 
# 6) Linear-plateau regression  
## a) Model

```{r mod4 model}
# Changing to sum-to-zero contrast
options(contrasts = c("contr.sum", "contr.poly"))

reg_dfw #to see variable names which we will use to fit the model

# Model fitting
#To fit non-linear model, we use the function "nlme()" which stands for non-linear mixed-effect model
mod4_linp <- nlme(yield_mgha ~ SSlinp(sr_ksha, a, b, xs), #SSlinp() [from package "nlraa"] non-linear function is used to fit the points of the linear-plateau model: a = intercept, b = slope, xs = break point for the plateau on x-axis #a, b, xs are not columns in our data set, these are parameters that we are asking for this SSlinp() function to iterate over, and estimate for us
                  data = reg_dfw,
                  random = list(rep = pdDiag(a + b + xs ~ 1)), #this function is creating a diagonal matrix, saying that for rep, I want the effect of the parameters of the model is calculating for us which is a (the intercept), b (the slope), and xs (the break point) to be random in respect to rep
                  fixed = list(a ~ 1,
                               b ~ 1,
                               xs ~ 1), #this is to say that the fixed part of the model, we want an estimate for the a (the intercept), b (the slope), and xs (the break point) 
                  start = c(a = 0, 
                            b = 0.3,
                            xs = 100)) #to provide some starting values #By visual inspection, how to find and specify the starting values: in the quadratic model, we see that the "Estimate" of the intercept is -0.9759850 (i.e., -1), so 0 is not a bad starting point; the "Estimate" of the slope for the quadratic model is 0.3089371, so that's why we take the starting point of the slope (i.e., b) as 0.3; for the break point, we see that the point of maximum is around 90 or 100 along the x-axis in the quadratic model curvature #After trying these values, if it does not work (i.e., if we try them, and the model says it did not converge), we can play around with different values and try to get the model to converge

#After running the model, we did not get any error in this case. If for some reason, if the model did not converge, we would get a message like "convergence was not achieved", so we would know that we have to change our starting values

#nlme() - stands for "non linear mixed effect" #a, b, xs are non-linear parameters: a = intercept, b = slope, xs = break point of the plateau

# Summary
summary(mod4_linp)
```

In the first "data.frame" output panel, the AIC, BIC, and logLik (log likelihood) are some model fit matrix.

In the second "data.frame" output panel, the "value" column is the actual estimate of what the model found for a, b, and xs (non-linear parameters: a = intercept = 3.45726, b = slope = 0.13603, xs = break point of the plateau = 73.47709). 

Note: These estimates (a = intercept = 3.45726, b = slope = 0.13603, xs = break point of the plateau = 73.47709) are basically iterations that the model ran for us to look for the values that we got i.e., they are going through a iterative process because the model is trying to optimize all three estimate at the same time. That's why we have to give starting values, and in this case we use the "SSlinp()" function to do that for us. 

## b) Model Assumptions
```{r mod4 augmenting}
# Augmenting and adding pearson standardized residuals
mod4_linp_aug <- augment(mod4_linp,
                         data = reg_dfw) %>% #We use "augment()" function to get all the residual information alongside our original data set
  mutate(.stdresid = resid(mod4_linp, #We use the "standardized" residual mostly for outlier detection
                           type = "pearson", 
                           scaled = T))


mod4_linp_aug
```

### Within-group errors are iid ~ N(0, var2)

```{r mod4 Standardized Residuals vs. Fitted}
ggplot(mod4_linp_aug, 
       aes(x = .fitted, 
           y = .stdresid))+
  geom_hline(yintercept = 0, color = "red")+
  geom_point(size = 3, alpha = .7)+
  geom_smooth(method = "lm")
```
The fitted vs. residual plot looks pretty similar to the quadratic model, which means that this linear-plateau (LP) model is also a good candidate.

Looking good.  

```{r mod4 Quantile-Quantile}
#Very important note: if we run any of the previous code chunks more than once, we will get the following error: "Error: object 'mod4_linp_randeff' not found". This happens because the residual column gets renamed incrementally (e.g., mod4_linp_randeff1, mod4_linp_randeff2) every time we rerun the code chunks for an extra time. Hence, if you get this error "Error: object 'mod4_linp_randeff' not found", clean all variables from the environment by clicking on the broom button, the rerun all previous code chunks by pressin the downward triangle ("Run All Chunks Above" button) on the current code chunk, then press the play button ("Run Current Chunk" button), and this time the code will run just fine.
ggplot(mod4_linp_aug, 
       aes(sample = .stdresid))+
  stat_qq()+
  stat_qq_line()
```
Looking good.  

## Very important note: 

if we run any of the previous code chunks more than once, we will get the following error: "Error: object 'mod4_linp_randeff' not found". This happens because the residual column gets renamed incrementally (e.g., mod4_linp_randeff1, mod4_linp_randeff2) every time we rerun the code chunks for an extra time. Hence, if you get this error "Error: object 'mod4_linp_randeff' not found", clean all variables from the environment by clicking on the broom button, the rerun all previous code chunks by pressin the downward triangle ("Run All Chunks Above" button) on the current code chunk, then press the play button ("Run Current Chunk" button), and this time the code will run just fine.

### Random effects are iid ~ N(0,var1)

On this plot, looking for normality.

```{r mod4 QQ plot for Rep random effect}
mod4_linp_randeff <- ranef(mod4_linp) %>% #The output of this current chunk is an array (not a data frame); So, we need to transform it into a data frame by using "as.data.frame()" function so that we can plot the data frame in ggplot() [because "ggplot()" only takes data frames to plot the data]
  as.data.frame()

ggplot(mod4_linp_randeff, 
       aes(sample = estimate))+
  stat_qq()+
  stat_qq_line() +
  facet_wrap(.~term) #"facet_wrap()" to plot the 3 terms i.e., a, b, xs in 3 separate plots

```
b and xs random estimates are so small that seem to be all zero.  
That's not a problem per se, just a fact around their variability.  

## c) Model summary
```{r mod4 ANOVA}
summary(mod4_linp)

```

a, b, and xs are highly significant!

## d) Final plot

```{r mod4 final plot}
ggplot(mod4_linp_aug, 
       aes(x = sr_ksha, 
           y = yield_mgha))+
  geom_point(size = 3, alpha = .7)+
  geom_line(aes(y = .fixed), 
            color = "forestgreen")

```

Problems with the plot:   
- regression curve on the plot above is not continuous because it is based on our original levels of SR (40, 60, 80, 100, 120 k seeds/ha).

-   similar to linear regression, no confidence interval.

Solutions:   
- to create a smoother look, we can simulate some SR data, use the model above to predict their yield, and plot that as a line.

-   we can use bootstrap to create confidence intervals around the regression curve

```{r mod4 better final plot}
# Creating predictions
nd <- nd %>%
  mutate(mod4_yield_mgha = predict(mod4_linp, 
                                   nd, 
                                   level = 0))  

# Non-linear prediction function  
predict.fun.nl <- function(x) predict(x,
                           newdata = nd,
                           re.form = NA,
                           level = 0)


# Bootstrapping
mod4_linp_boots <- boot_nlme(mod4_linp, 
                             f = predict.fun.nl, 
                             R = 200) %>%
  confint() %>%
  as.data.frame() %>%
  rename(mod4_linp_lcl = `2.5 %`,
         mod4_linp_upl = `97.5 %`)

nd <- nd %>%
  bind_cols(mod4_linp_boots)

nd

# Final plot
ggplot(reg_dfw, 
       aes(x = sr_ksha, 
           y = yield_mgha))+
  geom_point(size = 3, alpha = .7)+
  geom_line(data = nd, 
            aes(y = mod4_yield_mgha), 
            color = "forestgreen")+
  geom_ribbon(data = nd, aes(x = sr_ksha, 
                             ymin = mod4_linp_lcl,
                             ymax = mod4_linp_upl),
              fill = "gray", 
              alpha = 0.5, 
              inherit.aes = FALSE)



```

# 7) Model comparison  
## a) Visual comparison  

```{r comparison plot}

nd #To bring and show all the fit lines for the 4 models, we created nd in the very beginning and kept overwriting on it just so we can have a single object that have all the model predicted values and the Confidence Levels for each models. #To see the column names that we will use to plot

ggplot(reg_dfw, aes(x = sr_ksha, y = yield_mgha))+
  geom_point(size = 4, alpha = .6) +
  geom_line(data = nd,
            aes(y = mod1_yield_mgha, x = sr_ksha),
            color = "forestgreen",
            linewidth = 1.5) + #Adding line fit for the first model
  geom_line(data = nd,
            aes(y = mod2_yield_mgha, x = sr_ksha),
            color = "blue",
            linewidth = 1.5) + #Adding line fit for the second model
  geom_line(data = nd,
            aes(y = mod3_yield_mgha, x = sr_ksha),
            color = "purple",
            linewidth = 1.5) + #Adding line fit for the third model
   geom_line(data = nd,
            aes(y = mod4_yield_mgha, x = sr_ksha),
            color = "orange",
            linewidth = 1.5) #Adding line fit for the fourth model

```


## Table comparison  

```{r}
IC_tab(mod1_int,
       mod2_lin,
       mod3_quad,
       mod4_linp
       )

#IC_tab() function comes from "nlraa" package

```
Dr. Bastos: Based on the above, model 4 (linear-plateau) had the lowest AIC and thus should be used to find the optimum level of seeding rate. The lower the AIC, the better. 

Detained explanations:

- AIC and BIC (Bayesian Information Criterion) are different types of information criterion. 
- If we have the same data and we are just changing the model,AIC can help us which model has the best fit.  (we could have used R2 and/or MSE).
- AIC, AICc, and BIC are all information criterion that take into account how many variables you have in the model. 
- For R2, the more variable we add in the model, the R2 in going to increase even though some of those variables explain very little information about our response variable y. 
- However, AIC, AICc, and BIC these information criterion, they take a penalty for each argument we add in the model. 
- So, if we add another explanatory variable in the model, our fit matrices will only improve if the amount of information (or, the amount of variance) that the extra variable is explaining is higher than the degree of freedom (df) it is consuming.
- So, these AIC, AICc, and BIC information criterion adds a penalty -- meaning that if we add an explanatory variable that explains yield very little or may be this explanatory variable has no relationship with yield, our fit matrices will actually decrease, because we are consuming degrees of freedom and not explaining much (variance/variation) by adding this variable.
- The concept here is our fit matrices (AIC, AICc, and BIC) only improve  if the amount of variance that the extra parameter that was included in the model is actually worth it.
- If we add an explanatory variable that did not explain much of variance, then our fit matrices (AIC, AICc, and BIC) decrease/deteriorate.
- The lower are the fit matrices (AIC, AICc, and BIC), the better. 
- The models that have the lowest value (for AIC, AICc, and BIC) would be the model which would fit the data the best. 
- In this case (from the output), (very surprisingly) the linear-plateau (LP) model has the lowest values for all fit matrices i.e., AIC, AICc, and BIC. 
- It does not always happen this way, maybe sometimes some of the rankings will change depending on which one of these three fit matrices among AIC, AICc, and BIC to look into. 
- BIC is more conservative, AIC is more liberal. AICc is just a transformation of AIC which makes it a little bit conservative that AIC.
- But in this case, regardless of which fit matric among AIC, AICc, and BIC we use, all agree that lowest fit matric value is for linear-plateau (LP) model.
- Based on this, if we were purely using statistics i.e., fit matrices AIC, AICc, and BIC to decide which model to use now to estimate our optimum, then we would go with linear-plateau (LP) model, and that's what we would use to carry out our further analysis.
- If we run a differnt data set, and the ranking changes depending on the fit matric (i.e., AIC, AICc, and BIC), as long as we choose one particular fit matric and explain that fit matric, we should be fine. On a paper for example, we will mention that "the best model was selected based on the lowest AIC (or BIC) value", and reviewers will not have an issue with that as long as we choose one fit matric and explain which fit matic it was.


# 8) Optimum on best model  
Because our best model was the linear-plateau, let's find its seeding rate that optimized yield.  

```{r optimum SR}
mod4_linp %>% #mentioning the linear-plateau (LP) model
  intervals(which = "fixed") #to see the error around the fixed part of the model which one of them is the break point to understand the error/variability around the point estimate

```


Based on the linear-plateau model, the level of seeding rate to optimize corn grain yield in this study was **73.47** thousand seeds/ha.  

Now let's predict what was the yield at that seeding rate.  


```{r yield at optimum SR}

#We use "predict()" to know the yield level at the seeding rate [73.47 thousand seeds/ha]

predict(mod4_linp, #specifying the model
        newdata = data.frame(sr_ksha = 73.48),
        level = 0 #to get an estimate only on the general level of the model (and to exclude random level of the model)
        )

```
At the optimum seeding rate of **73.47** thousand seeds/ha, corn grain yield was **13.45** Mg/ha.

```{r final plot}
ggplot(reg_dfw, aes(x = sr_ksha, y = yield_mgha))+
  geom_point(size = 4, alpha = .6)+
  geom_line(data = nd, aes(y = mod4_yield_mgha), 
            color = "orange",
            size = 1.5) 

```
# 9) Take-home  

-   We use regression when both y and x are **numerical**  

-   Finding optimum: should run multiple models, see which one fits the data best, and choose that one to estimate optimum

-   Always check residuals! p-values alone do not tell you whether model is adequate for your data!



